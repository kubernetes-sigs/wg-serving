# Catalog

| Kind | Model Server                                       | Model       | Provider | README Link                                                     |
| --- |----------------------------------------------------|-------------| --- |-----------------------------------------------------------------|
| Deployment | [vLLM](https://github.com/vllm-project/vllm)       | gemma-2b    | GKE | [README](./core/deployment/vllm/gemma-2b/gke/README.md)         |
| Deployment | [vLLM](https://github.com/vllm-project/vllm)       | llama3-8b   | GKE | [README](./core/deployment/vllm/llama3-8b/gke/README.md)        |
| Deployment | [vLLM](https://github.com/vllm-project/vllm)       | llama3-70b  | GKE | [README](./core/deployment/vllm/llama3-70b/gke/README.md)       |
| Deployment | [JetStream](https://github.com/google/JetStream)   | gemma-7b-it | GKE | [README](./core/deployment/jetstream/gemma-7b-it/gke/README.md) |
| InferenceService | [KServe sklearn](https://github.com/kserve/kserve) | iris        |  | [README](./kserve/examples/sklearn-iris/README.md)              |
| InferenceService | [KServe vLLM](https://github.com/kserve/kserve)    | XXX         |  | [README](./kserve/examples/vllm/README.md)                      |:wq


